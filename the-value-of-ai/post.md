---
title: "The Value Of AI"
subtitle: "Identifying why LLMs are valuable, and where this matters"
---

<!------------------------- REFERENCE LINKS BLOCK ----------------------------------->
<!----------------------- END REFERENCE LINKS BLOCK --------------------------------->

![](./images/image.png)

I think a lot of people miss why the LLM revolution is such a big deal.

I assert it's:

1. The ability to handle unstructured, ambiguous data
2. The ability to follow up

### The value of ambiguity
Before LLMs, the way to use a computer was through structured input. I had to fill out a field, drag a thing, press a button.

Machines need definite, precise instructions, so humans had to interact in definite, precise ways.

Meaning, only those who warped their brains to think in definite, precise ways were good at communicating with the machines (which I've written about [before](https://mieubrisse.substack.com/p/let-programming-burn)).

But as anyone who's filled out a form with unnecessary "Required" fields knows, precision is expensive.

Think of language: we say something, and if it's unclear we clarify by adding context and resolving ambiguity. If we mess up, we say "Oops, not what I meant."

That's fine 98% of the time.

Only in 2% of the cases do we bust out the heavyweight tools: legalese, context-free grammars, etc.

The ambiguity is a speed feature, not a bug.

And now the LLM revolution has unlocked this ease to interacting with the machine.

We can talk to the machine with "good enough".

We can use the machine like we're painting: broad strokes, then refine when necessary.

Just consider what Googling entails:

I have to:

1. Translate my query into search engine-ese ("American revolution founder age")
1. Identify candidates that look promising among results ranked by someone else
1. Hope that the result - written in a way that made sense to the author, not me - is useful for my purposes
1. If I don't find what I want, debug why I didn't get what I want (was my search engine-ese not good enough? do the results just not exist) and repeat the process from the top

LLMs let me query in my natural language, and if I need more info I can ask the LLM to explain as many times as I need in ways that make the most sense to me ("explain it like I'm five", "use examples", "use examples from my own life").

No wonder Google is scared.

TODO SUBSCRIBE BUTTON

Of course, the common objection is that LLMs hallucinate, and make errors.

This is true. But we already have tools to handle errors, because humans make errors too.

Think guardrails like:

- Undo
- Forcing a choice from a defined list
- Reviewing changes before executing
- Version control

Ask any digital artist: undo alone makes producing what you want orders of magnitude easier.

I think the spread of LLMs will result in even better guardrails (e.g. [a council of LLMs for verifying things](https://github.com/haizelabs/verdict)).

That seems great: we'll all become "computer painters" rather than "computer users".

### What this means
Recognizing _why_ LLMs are powerful, we can use first principles to identify areas where LLMs could be disruptive:

- **Where both information input and speed are important:** a census-taker, a soldier, a patient registrar at an emergency room
- **Any search-and-refine flow:** searching the web, researching scientific papers, analyzing data in a database, shopping on Amazon
- **Where input is unstructured:** email, text messages/DMs, [book notes](https://mieubrisse.substack.com/p/categorizing-book-notes-with-ai), videos & voice recordings, blog posts, PDFs, the results of some APIs I've encountered (ðŸ’€)
- **Where imprecision + undo feels smoother than precision:** processing your email or TODO inbox, adding items to a shopping cart, navigating a website 
- **Where happy accidents enrich the final product:** image/video generation (obviously), interior design, writing, restaurant or apartment-hunting
- **Information expansion workflows:** adversarial empathy in negotiations, finding disconfirming evidence to theories, brainstorming

And we haven't even seen how deep the rabbit hole goes.

Until 4 years ago, interacting with the computer meant definite language so all our computer interfaces are oriented around specificity.

What happens when ambiguity is treated as a tool, to be employed when speed matters and discarded when precision matters?

What happens when [all the AI tools can communicate between themselves like humans do](https://plainenglish.io/eli5/what-is-model-context-protocol)?

I'm excited to find out.

TODO SUBSCRIBE BUTTON

<!------------------ IG POST DESCRIPTION --------------------->
<!--
TODO

ðŸ‘‰ Read the full article (link in bio)

#hashtag1 #hashtag2 #hashtag3
-->

<!-------------------- IG STORY TEXT ------------------------->
<!--
TODO
-->
