---
title: "The Value Of AI"
subtitle: "Why LLMs are valuable, and where this matters"
---

<!------------------------- REFERENCE LINKS BLOCK ----------------------------------->
<!----------------------- END REFERENCE LINKS BLOCK --------------------------------->

![](./images/image.png)

I think people miss why the LLM revolution is such a big deal.

They think itâ€™s just summaries and human-like conversations.

I assert it's mastery of ambiguity.

### The value of ambiguity
Before LLMs, the way to use a computer was through structured input. Fill out a field, press a button, drag a thing.

Machines speak definite, precise language so humans had to too.

Meaning, only those who warped their brains to think in definite, precise ways were good at computers ([and now they're losing market share](https://mieubrisse.substack.com/p/let-programming-burn)).

But anyone who's filled out a form with excessive "Required" fields knows that precision is expensive.

Think about our language.

We say something, and if it's unclear we clarify by adding context, resolving ambiguity. If we mess up we say "Oops, not what I meant."

We are naturally iterative communicators. And it's fine 98% of the time.

Only 2% of the time do we bust out the precision: legalese, code, etc.

The ambiguity is a speed feature, not a bug.

And now LLMs let the machine do the same.

We can talk to computers with "good enough".

We can interact with tech like we're painting: broad strokes, then refine when necessary.

Consider how much Google **is not** this. I have to:

1. Translate my query into search engine-ese ("American revolution founder age")
1. Identify results that look promising among a list ranked by someone else
1. Hope the results - written in a way that made sense to the authors, not me - are useful for me
1. If they're not, debug why (was my search engine-ese not good enough? does what I'm looking for just not exist?)
1. Repeat from the top

I'm not painting. I'm carving a scalpel through a realm I don't understand.

LLMs skip all that.

I query in my language. I get results in my language.

When I don't understand, I drill in. Get 40 different explanations until I do.

Go slowly. Explain it like Iâ€™m five. Use examples from my own life.

No wonder Google is scared.

TODO SUBSCRIBE BUTTON

The common objection is that LLMs make errors, hallucinate. True.

But we have tooling for this, because humans make errors them all the time.

Guardrails like:

- "Oops, not what I meant"
- Undo
- Ask for multiple opinions
- Forcing a choice from a defined list
- Reviewing changes before executing
- Version control

LLMs will put pressure to make these guardrails even better (e.g. [a council of LLMs for verifying things](https://github.com/haizelabs/verdict)).

I'm all for it.

Forget being a computer user; I want to be a computer painter.

### What this means
If we know _why_ LLMs are powerful, we can identify areas where they can be disruptive:

- **Where speed of information input is important:** a census-taker, a soldier, a patient registrar in the emergency room
- **Search-and-refine flows:** searching the web, doing research, analyzing data, shopping on Amazon
- **Where input is unstructured:** email, text messages, [book notes](https://mieubrisse.substack.com/p/categorizing-book-notes-with-ai), video & voice recordings, blog posts, PDFs, the results of some APIs I've encountered ðŸ’€
- **Where imprecision + undo feel better than precision:** processing your email, processing your TODO inbox, blocking your calendar, adding items to a shopping cart, navigating a website 
- **Where happy accidents enrich the result:** image/video generation, interior design, writing, restaurant- or apartment-hunting
- **Information expansion workflows:** adversarial empathy in negotiations, surfacing disconfirming evidence to theories, brainstorming

And that's just what I could think of. We don't yet know how deep the rabbit hole goes.

Until 4 years ago, interacting with the computer required precision so all our computer interfaces are oriented around specificity.

What happens when the _default_ computer interaction is ambiguous: fast and iterative by default, slow and precise only when it matters?

What new opportunities emerge?

I'm excited to find out.

TODO SUBSCRIBE BUTTON

<!------------------ IG POST DESCRIPTION --------------------->
<!--
TODO

ðŸ‘‰ Read the full article (link in bio)

#hashtag1 #hashtag2 #hashtag3
-->

<!-------------------- IG STORY TEXT ------------------------->
<!--
TODO
-->
